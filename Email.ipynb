{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51c7be3",
   "metadata": {},
   "source": [
    "\n",
    "# Email Classification Notebook (Rebuilt)\n",
    "\n",
    "This notebook was reconstructed from a Python script pasted from Colab to fix the error:\n",
    "> **\"Invalid Notebook â€” The Notebook Does Not Appear to Be Valid JSON\"**\n",
    "\n",
    "All cells below mirror your original workflow (data download, cleaning, feature engineering, modeling, and Streamlit app scaffolding). You can run them step-by-step in Jupyter or Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f27860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: clean environment (disabled by default)\n",
    "# !rm -rf /content/*\n",
    "\n",
    "!pip install --upgrade --no-cache-dir gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ac0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download source files from Google Drive (uncomment/adjust as needed)\n",
    "# Links you previously used:\n",
    "# https://drive.google.com/file/d/1tFWUoD4mxga4KTVRRQcF8ZuIZD-KkgMr/view?usp=sharing\n",
    "# https://drive.google.com/file/d/1RrXMsrppQnKb0Absnr9EDQ4wygAYvOnh/view?usp=sharing\n",
    "# https://drive.google.com/file/d/1_JEJ-2uszpe9p_eOEHYRE9fkEmElgng5/view?usp=sharing\n",
    "# https://drive.google.com/file/d/1kNZ7dt8M0sxk5aSLA3utzqG4XS_czyaP/view?usp=sharing\n",
    "\n",
    "# Uncomment if you need to re-download in Colab:\n",
    "# !gdown https://drive.google.com/uc?id=1_JEJ-2uszpe9p_eOEHYRE9fkEmElgng5\n",
    "# !gdown https://drive.google.com/uc?id=1kNZ7dt8M0sxk5aSLA3utzqG4XS_czyaP\n",
    "# !gdown https://drive.google.com/uc?id=1tFWUoD4mxga4KTVRRQcF8ZuIZD-KkgMr\n",
    "# !gdown https://drive.google.com/uc?id=1RrXMsrppQnKb0Absnr9EDQ4wygAYvOnh\n",
    "\n",
    "# If you downloaded a zip named archive.zip:\n",
    "# !unzip -o /content/archive.zip && rm -f /content/archive.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a265a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import email\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the raw emails CSV\n",
    "# Adjust the path if needed\n",
    "df = pd.read_csv(\"/content/emails.csv\")\n",
    "\n",
    "# Save a sample email body to file (optional)\n",
    "idx = 112233 if len(df) > 112233 else 0\n",
    "with open('/content/sample_email.txt','w') as f:\n",
    "    f.write(df['message'].values[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecdec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explore a single email\n",
    "message = df.loc[1, 'message']\n",
    "e = email.message_from_string(message)\n",
    "\n",
    "print(\"Headers:\", e.items())\n",
    "print(\"Date:\", e.get('Date'))\n",
    "print(\"Subject:\", e.get('Subject'))\n",
    "print(\"Body (raw payload):\", e.get_payload()[:500], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a98194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_field(field, messages):\n",
    "    column = []\n",
    "    for m in messages:\n",
    "        e = email.message_from_string(m)\n",
    "        column.append(e.get(field))\n",
    "    return column\n",
    "\n",
    "df['date'] = get_field(\"Date\", df['message'])\n",
    "df['subject'] = get_field(\"Subject\", df['message'])\n",
    "df['X-Folder'] = get_field(\"X-Folder\", df['message'])\n",
    "df['X-From'] = get_field(\"X-From\", df['message'])\n",
    "df['X-To'] = get_field(\"X-To\", df['message'])\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004253a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def body(messages):\n",
    "    column = []\n",
    "    for m in messages:\n",
    "        e = email.message_from_string(m)\n",
    "        column.append(e.get_payload())\n",
    "    return column\n",
    "\n",
    "df['body'] = body(df['message'])\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17edc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'file' in df.columns:\n",
    "    def employee(file_series):\n",
    "        column = []\n",
    "        for string in file_series:\n",
    "            try:\n",
    "                column.append(string.split(\"/\")[0])\n",
    "            except Exception:\n",
    "                column.append(np.nan)\n",
    "        return column\n",
    "\n",
    "    df['employee'] = employee(df['file'])\n",
    "    df.head(3)\n",
    "else:\n",
    "    print(\"Column 'file' not found in df; skipping employee extraction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71310c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Rows:\", df.shape[0])\n",
    "if 'X-Folder' in df.columns:\n",
    "    print(\"Unique folders:\", df['X-Folder'].nunique())\n",
    "    unique_emails = pd.DataFrame(df['X-Folder'].value_counts()).reset_index()\n",
    "    unique_emails.columns = ['folder_name', 'count']\n",
    "    display(unique_emails.head(20))\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x='count', y='folder_name', data=unique_emails.iloc[:20, :], palette=\"Blues_d\")\n",
    "    plt.title(\"Top 20 folders\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Folder_Name\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'X-Folder' not found; skipping folder analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5387079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'employee' in df.columns:\n",
    "    top_20 = pd.DataFrame(df['employee'].value_counts()[:20]).reset_index()\n",
    "    top_20.columns = [\"Employee_name\", \"Counts\"]\n",
    "    display(top_20)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(y=\"Employee_name\", x=\"Counts\", data=top_20, palette=\"Blues_d\")\n",
    "    plt.title(\"Top 20 highest email sender employees\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Employee_name\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'employee' not found; skipping top senders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dateutil import parser\n",
    "\n",
    "def change_type(dates):\n",
    "    column = []\n",
    "    for d in dates:\n",
    "        try:\n",
    "            column.append(parser.parse(d).strftime(\"%d-%m-%Y %H:%M:%S\"))\n",
    "        except Exception:\n",
    "            column.append(np.nan)\n",
    "    return column\n",
    "\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = change_type(df['date'])\n",
    "\n",
    "def preprocess_folder(folders):\n",
    "    column = []\n",
    "    for folder in folders:\n",
    "        if (folder is None or folder == \"\"):\n",
    "            column.append(np.nan)\n",
    "        else:\n",
    "            try:\n",
    "                column.append(folder.split(\"\\\\\")[-1].lower())\n",
    "            except Exception:\n",
    "                column.append(np.nan)\n",
    "    return column\n",
    "\n",
    "if 'X-Folder' in df.columns:\n",
    "    df['X-Folder'] = preprocess_folder(df['X-Folder'])\n",
    "\n",
    "def replace_empty_with_nan(series):\n",
    "    column = []\n",
    "    for val in series:\n",
    "        if (val == \"\") or (val is None):\n",
    "            column.append(np.nan) \n",
    "        else:\n",
    "            column.append(val)\n",
    "    return column\n",
    "\n",
    "for col in ['subject','X-To']:\n",
    "    if col in df.columns:\n",
    "        df[col] = replace_empty_with_nan(df[col])\n",
    "\n",
    "# Drop rows with any missing values (as in your script)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Drop columns not needed\n",
    "cols_to_drop = [c for c in ['file','message','date','X-From','X-To','employee'] if c in df.columns]\n",
    "df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"/content/cleaned_data.csv\", index=False)\n",
    "print(\"Saved cleaned data -> /content/cleaned_data.csv. Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec5ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re, string, time\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "df = pd.read_csv(\"/content/cleaned_data.csv\")\n",
    "\n",
    "# Keep folders with more than n emails\n",
    "def remove_folders(emails_df, n=150):\n",
    "    email_count = dict(emails_df['X-Folder'].value_counts())\n",
    "    small_folders = [key for key, val in email_count.items() if val <= n]\n",
    "    emails = emails_df.loc[~emails_df['X-Folder'].isin(small_folders)]\n",
    "    return emails\n",
    "\n",
    "if 'X-Folder' in df.columns:\n",
    "    df = remove_folders(df, 150)\n",
    "\n",
    "# combine subject + body\n",
    "if {'subject','body'}.issubset(df.columns):\n",
    "    df['text'] = df['subject'].astype(str) + \" \" + df['body'].astype(str)\n",
    "    df.drop(['subject','body'], axis=1, inplace=True)\n",
    "else:\n",
    "    print(\"Columns 'subject'/'body' not found; ensure they exist before combining.\")\n",
    "\n",
    "def preprocess(x):\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'\\n+', ' ', x)\n",
    "    x = re.sub(\"[\"+string.punctuation+\"]\", \" \", x)\n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "    return x\n",
    "\n",
    "t0 = time.time()\n",
    "df['text'] = df['text'].map(preprocess).apply(lambda s: ' '.join([w for w in s.split() if w not in stop]))\n",
    "print(\"Preprocess time (sec):\", time.time() - t0)\n",
    "\n",
    "# (Optional) Filter to specific labels if desired\n",
    "# labels = ['management','calender','logistics','corporate','online trading','universities','it']\n",
    "# df = df[df['X-Folder'].isin(labels)].reset_index(drop=True)\n",
    "\n",
    "df.to_csv(\"/content/preprocessed.csv\", index=False)\n",
    "print(\"Saved preprocessed data -> /content/preprocessed.csv. Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q sentence-transformers\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "data = pd.read_csv(\"/content/preprocessed.csv\")\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "text_data = data['text'].astype(str).tolist()\n",
    "embs = []\n",
    "for t in tqdm(text_data, total=len(text_data)):\n",
    "    embs.append(model.encode(t).ravel().tolist())\n",
    "\n",
    "emb_df = pd.DataFrame(embs)\n",
    "emb_df['class'] = data['X-Folder'].values.tolist()\n",
    "emb_df.to_csv('/content/emb_data.csv', index=False)\n",
    "print(\"Saved embeddings -> /content/emb_data.csv. Shape:\", emb_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('/content/emb_data.csv')\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101, stratify=y)\n",
    "\n",
    "model_obj = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(class_weight='balanced', n_jobs=-1, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "acc_lr = balanced_accuracy_score(y_test, y_pred_lr)\n",
    "model_obj[acc_lr] = clone(lr)\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(class_weight='balanced', random_state=101)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "acc_dt = balanced_accuracy_score(y_test, y_pred_dt)\n",
    "model_obj[acc_dt] = clone(dt)\n",
    "\n",
    "# Linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(C=1.0, class_weight='balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "acc_svc = balanced_accuracy_score(y_test, y_pred_svc)\n",
    "model_obj[acc_svc] = clone(svc)\n",
    "\n",
    "# Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(n_estimators=100, class_weight='balanced', random_state=101)\n",
    "etc.fit(X_train, y_train)\n",
    "y_pred_etc = etc.predict(X_test)\n",
    "acc_etc = balanced_accuracy_score(y_test, y_pred_etc)\n",
    "model_obj[acc_etc] = clone(etc)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=101)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "acc_rfc = balanced_accuracy_score(y_test, y_pred_rfc)\n",
    "model_obj[acc_rfc] = clone(rfc)\n",
    "\n",
    "print(\"Balanced Accuracies -> LR:{:.3f}  DT:{:.3f}  SVC:{:.3f}  ETC:{:.3f}  RFC:{:.3f}\"\n",
    "      .format(acc_lr, acc_dt, acc_svc, acc_etc, acc_rfc))\n",
    "\n",
    "# Pick best model\n",
    "best_score = max(model_obj.keys())\n",
    "best_model = clone(model_obj[best_score])\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_model, '/content/model.sav')\n",
    "print(\"Saved best model -> /content/model.sav  (score: {:.3f})\".format(best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41af718",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q streamlit==1.20.0 sentence-transformers\n",
    "\n",
    "# Creates a Streamlit app file (uncomment to write it out)\n",
    "app_code = r'''\n",
    "import os\n",
    "import streamlit as st\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import email as emlib\n",
    "import uuid\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    emb_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    pred_model = joblib.load(\"model.sav\")\n",
    "    return emb_model, pred_model\n",
    "\n",
    "def preprocess(x: str) -> str:\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'\\n+', ' ', x)\n",
    "    x = re.sub(\"[\"+string.punctuation+\"]\", \" \", x)\n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "    return x\n",
    "\n",
    "emb_model, pred_model = load_models()\n",
    "\n",
    "def predict_email_class2(subject, body):\n",
    "    s = (subject or \"\") + \" \" + (body or \"\")\n",
    "    s = preprocess(s)\n",
    "    arr = emb_model.encode(s).ravel()\n",
    "    cls = pred_model.predict([arr])[0]\n",
    "    return cls\n",
    "\n",
    "st.title(\"Email Classification Web App\")\n",
    "mode = st.selectbox(\"Input Mode\", [\"Upload .txt\", \"Type Manually\"], index=0)\n",
    "\n",
    "subject = \"\"\n",
    "body = \"\"\n",
    "file = None\n",
    "\n",
    "if mode == \"Upload .txt\":\n",
    "    file = st.file_uploader(\"Upload a plain-text email file\", type=[\"txt\"])\n",
    "else:\n",
    "    subject = st.text_input(\"Subject\")\n",
    "    body = st.text_area(\"Body\", height=200)\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    if file is not None:\n",
    "        s = file.read().decode(\"utf-8\")\n",
    "        e = emlib.message_from_string(s)\n",
    "        subj = e.get(\"Subject\", \"\")\n",
    "        payload = e.get_payload()\n",
    "        pred = predict_email_class2(subj, payload)\n",
    "        st.success(f\"Predicted folder/class: {pred}\")\n",
    "    else:\n",
    "        pred = predict_email_class2(subject, body)\n",
    "        st.success(f\"Predicted folder/class: {pred}\")\n",
    "'''\n",
    "\n",
    "with open('/content/app.py', 'w') as f:\n",
    "    f.write(app_code)\n",
    "\n",
    "print(\"Wrote Streamlit app to /content/app.py\")\n",
    "print(\"Run with:  streamlit run /content/app.py --server.port 8501\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
